# -*- coding: utf-8 -*-
"""final_bio

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/134NHlUHt8NnX3oeyn4Lctgzpx5OJSdlC
"""

import random
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; sns.set(style='whitegrid')
import plotly.express as px
import plotly.graph_objects as go
from matplotlib import cm
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, roc_curve, roc_auc_score
from sklearn.metrics import balanced_accuracy_score
from numpy import mean
from numpy import absolute
from numpy import sqrt
from sklearn import svm
from sklearn.metrics import auc
from sklearn.metrics import RocCurveDisplay
from sklearn.model_selection import StratifiedKFold
from collections import Counter

from sklearn.model_selection import KFold,StratifiedKFold
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score
from sklearn import preprocessing
from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN

# Machine Learning Models
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
from sklearn.ensemble import VotingClassifier

from pandas.core.common import random_state

random.seed(1)

def dict_sum(dictlist):
  outdic = {}
  for d in dictlist:
    for k in d.keys():
      outdic[k] = 0
  for d in dictlist:
    for k in d.keys():
      outdic[k]+=d[k]
  return outdic

# Class for Sequence Operations 
class SQ: 
    
    def __init__ (self, seq=None, seq_type = "DNA"): 
        self.seq = seq.upper()
        self.seq_type = seq_type
          
    # class instance operations
    def __len__(self):
        return len(self.seq)
    def __getitem__(self, n):
        return self.seq[n]
    def __getslice__(self, i, j):
        return self.seq[i:j]
    def __str__(self):
        return self.seq
    
    # Frequency of Sybols 
    def freq(self,compare=None,show_id='perc',fheight=None,fwidth=None):
        
        if(compare is not None):
            if(self.seq_type != compare.seq_type):
                print('sequences are not of same type')
                return None
            
        c1 = dict(Counter(self.seq))  # abc counter for s1
        if(compare is not None):
            c2 = dict(Counter(compare))  # abc counter for s2
            
        abc = list(self.abc())
        count = Counter(abc)
        abc_c = dict(Counter({x:0 for x in count}))
        
        c_all1 = dict_sum([c1,abc_c])
        if(compare is not None):
            c_all2 = dict_sum([c2,abc_c])    

        lst = []
        for i in c_all1.keys():
           if(self.seq_type == 'DNA' or self.seq_type == 'mRNA'):
               lst.append(dic_map('iupac_nucleotide',i))
           elif(self.seq_type == 'PROTEIN'):
               lst.append(dic_map('iupac_amino',i))
                
        if(compare is not None):
            lst2 = []
            for i in c_all2.keys():
               if(self.seq_type == 'DNA' or self.seq_type == 'mRNA'):
                   lst2.append(dic_map('iupac_nucleotide',i))
               elif(self.seq_type == 'PROTEIN'):
                   lst2.append(dic_map('iupac_amino',i))
          
        perc = [round(x / len(self.seq),3) for x in [*c_all1.values()]]
        if(show_id is 'perc'):
            show1 = lst; show2 = perc
        elif(show_id is 'count'):
            show1 = lst; show2 = [*c_all1.values()]
        fig = go.Figure(go.Bar(y=show1,x=show2,
                               marker_color='rgb(26, 118, 255)',
                               orientation='h',text=show2,
                               textposition='outside',name='SEQ1'))
        if(compare is not None):
            perc = [round(x / len(compare),3) for x in [*c_all2.values()]]
            if(show_id is 'perc'):
                show1 = lst2; show2 = perc
            elif(show_id is 'count'):
                show1 = lst2; show2 = [*c_all2.values()]
            fig.add_trace(go.Bar(y=show1,x=show2,marker_color='rgb(55, 83, 109)',
                                 orientation='h',text=show2,
                                 textposition='outside',name='SEQ2'))
        fig.update_layout(template='plotly_white',height=fheight,width=fwidth,
                         title=f'<b>{self.seq_type} SEQUENCE CONTENT</b>',
                         font=dict(family='sans-serif',size=12),
                         margin=dict(l=40, r=40, t=50, b=10))
        fig.show()

    # Return % GC Nucleotides
    def gc(self):
        if (self.seq_type == "DNA" or self.seq_type == "mRNA"):
            ii = 0
            for s in self.seq:
                if(s in "GCgc"):
                    ii += 1
            return round(ii / len(self.seq),4)
        else:
            return None
        
    # General Sequence Info
    def get_seq_biotype (self):
        return self.seq_type
    def info(self):
        print (f"SEQ: {self.seq}" +" "+ f"TYPE: {self.seq_type}")
        
    # Get ABC
    def abc(self):
        if(self.seq_type=="DNA"): 
          return "ACGT"
        elif(self.seq_type=="mRNA"):
          return "ACGU"
        elif (self.seq_type=="PROTEIN"): 
          return "ACDEFGHIKLMNPQRSTVWY"
        else: 
          return None
        
    # Check Validity
    def validate(self,verbose=False):
        alp = self.abc()
        res = True; i = 0
        while (res and i < len(self.seq)):
            if self.seq[i] not in alp: 
                res = False
            else: i += 1
        if(res):
            if(verbose):
                print(f'{self.seq_type} is valid')
            return res
        else:
            if(verbose):
                print(f'{self.seq_type} is invalid')
            return res
        
    # Transcription 
    def transcription(self):
        if (self.seq_type == "DNA"):
            return SQ(self.seq.replace("T","U"), "mRNA")
        else:
            return None
    
    # Reverse Compliment
    def reverse_comp(self):
        
        if (self.seq_type != "DNA"): 
            print('input not DNA')
            return None
    
        lst_seq = ['A','T','G','C']
        lst_comp = ['T','A','C','G']
            
        comp = ''
        for char in self.seq:
            ii=-1
            for c in lst_seq:
                ii+=1
                if(char == c ):
                    comp = lst_comp[ii] + comp
            
        return SQ(comp, "DNA")
        
    # Translate 
    def translate(seq,p0=0):
        seq_aa = ""
        for pos in range(p0,len(seq)-2,3):
            cod = seq[pos:pos+3]
            seq_aa += dic_map(map_id='codon',tid=cod)
        return seq_aa
    # store all possible collections of amino acid groups 
    # in all 6 frames
    def frames(self):
        res = []
        for i in range(0,3):
            res.append(self.translate(self.seq,i))
        rc = self.reverse_comp()
        for i in range(0,3):
            res.append(self.translate(rc,i)) 
        return res
    # using the knowledge that it starts with M and ends with _, 
    # filter out rule breaking ORFs
    @staticmethod
    def all_proteins_RF(aa_seq):
        # aa_seq -> converted ORF
        current_prot = []
        proteins = []
        for aa in aa_seq:
            if(aa == "_"):
                if current_prot:
                    for p in current_prot:
                        proteins.append(p)
                    current_prot = []
            else:
                if(aa == "M"):
                    current_prot.append("")
                for i in range(len(current_prot)):
                    current_prot[i] += aa
        return proteins
    
    '''Computes all possible proteins for all ORF'''
    # and sort them based on size
    def ORF_protein(self, mins = 0):
        
        # order 
        def insert_prot_ord (prot, list_prots):
            i = 0
            while i < len(list_prots) and len(prot) < len(list_prots[i]):        
                i += 1
            list_prots.insert(i, prot)
        
        rfs = self.frames()  # get all ORF conversions
        res = []
        for rf in rfs:
            print(rf)
            prots = self.all_proteins_RF(rf) # return only protein cases
            # additionally sort based on protein size
            for p in prots: 
                if len(p) > mins: 
                    insert_prot_ord(p, res)
        return res
    
# Plot Correlation to Target Variable only
def corrMat(df,target='demand',figsize=(9,0.5),ret_id=False):
    
    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]
    corr_mat = corr_mat.transpose()
    corr = corr_mat.loc[:, df.columns == target].transpose().copy()
    
    if(ret_id is False):
        f, ax = plt.subplots(figsize=figsize)
        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, 
                     cmap=cmap,square=False,lw=2,annot=True,cbar=False)
        plt.title(f'Feature Correlation to {target}')
    
    if(ret_id):
        return corr

class get_unitigs:
    
    def __init__(self,verbose=True):
        self.df = pd.read_csv('metadata.csv', index_col=0) # metadata
        self.meta_names = self.df.columns 
        self.target_name = None
        self.verbose = verbose
        self.target = None
    
    # Get Unitig Feature matrix & Target Vector
    def get_case(self,phenotype=None):
    
        self.target_name = phenotype
        _metadata = self.df
        if(self.verbose):
            print(f'Target Antibiotic: {self.target_name}')
            print(f'Metadata df: {_metadata.shape}')
        
        # remove those that don't contain target values
        _metadata = _metadata.dropna(subset=[phenotype])
        self.metadata = _metadata.copy()
        
        if(self.verbose):
            print(f'Metadata df after na() removal {_metadata.shape}')
        _metadata = _metadata[phenotype] # choose target variable 
        
        # prefix = '../input/gono-unitigs/'
        suffix = '_gwas_filtered_unitigs.Rtab'
        
        if(self.verbose):
            print('\nCombining Metadata & Unitigs')
        
        # unitig feature matrix for phenotype
        tdf = pd.read_csv(phenotype + suffix, sep=" ", 
                          index_col=0, low_memory=False)
        # align column data w/ metadata df (pattern_id = sample_idd)
        tdf = tdf.T 
        # keep only common rows, ie. that have resistence measure]
        tdf = tdf[tdf.index.isin(_metadata.index)] 
        
        train = tdf
        self.target = _metadata[_metadata.index.isin(tdf.index)]

        self.X = pd.concat([train,self.target],axis=1)
        if(self.verbose):
            print(f'Unitig Matrix (+target): {self.X.shape}')

case = get_unitigs()

#creating a feature matrix for ciprofloxacin
case.get_case('cip_sr')

case_cip = case.X

cip_train = case_cip.drop('cip_sr',axis=1)

cip_target = case.X[case.target_name]

print("CIP class distribution : ",case_cip['cip_sr'].value_counts())

# Creating a function to get mic values from metadata
def get_mic():
    
    lst_cases = ['azm_mic','cip_mic','cfx_mic']
    rtabs = ['azm_sr','cip_sr','cfx_sr']
    lst_temp = []
    
    ii=-1
    for case in lst_cases:
        
        ii+=1
        case_id = get_unitigs(verbose=False)
        case_id.get_case(rtabs[ii])
        
        X_all = pd.concat([case_id.X,case_id.metadata],axis=1)
        
        new_df = X_all[case].value_counts().rename_axis(case).reset_index(name='counts')
        new_df = new_df.rename(columns={new_df.columns[0]: 'mic'})
        new_df['case'] = case                
        lst_temp.append(new_df)
        
    X_counts = pd.concat([lst_temp[0],lst_temp[1],lst_temp[2]],axis=0)
    X_counts.sort_values(by='mic',inplace=True,ascending=True)
    X_counts['mic'] = X_counts['mic'].astype(str)

    fig = px.bar(X_counts, x='mic',y='counts',color='case')
    fig.update_layout(template='plotly_white',height=300)
    fig.show()

get_mic()

case_unitigs = case.X.columns.tolist()
ii=-1
for i in case_unitigs:
    if(',' in i):
        ii+=1;print(f'{ii} | {i}')

lst_SQ = []
for unitig in case_unitigs:
    lst_SQ.append(SQ(unitig,'DNA'))
print("Total sequence data : ",len(lst_SQ))
lst_SQ = pd.DataFrame(lst_SQ)
print("Top 10 sequences : ", lst_SQ.head(10))

class mod_unitigs():
    
    def __init__(self,unitigs):
        self.X = unitigs.X # input data class
        self.target_name = unitigs.target_name
        self.verbose = True
      

    ''' Downsampling Class 0 using .sample & recompile '''
    # If there's too much of the dominant class, just downsample
    
    def split_case(self, frac_id=0.5, xtrain= cip_train, ytrain = cip_target):
        
        X = xtrain
        y = pd.Series(ytrain)
        XX = pd.concat([X,y],axis=1)
        
        lst_temp = dict(tuple(XX.groupby(self.target_name))) # divide classes
        ratio = lst_temp[0].shape[0]/lst_temp[1].shape[0] # get class ratio
        
        # Sample approach for downsizing majority class
        X_red = lst_temp[0].sample(frac=frac_id)
        X_all = pd.concat([X_red,lst_temp[1]],axis=0)
        
        if(self.verbose):
            print(f'Class 0 : {lst_temp[0].shape}')
            print(f'Class 1 : {lst_temp[1].shape}')
            print(f'Class Ratio: {round(ratio,4)}')
            print(f'Reduced Training Matrix: {X_all.shape}')
        
        # Redefine .train, .target
        self.target = X_all[self.target_name].copy()
        X_all.drop(self.target_name, inplace=True, axis=1)
        self.train = X_all
        
    ''' SMOTE UPSAMPLING '''
    # For unbalanced problems, synthetically/model new data
        
    def smote(self,smote_id = 'smotenc',
                   smote_strat=0.5,
                   k_neighbours=5, xtrain= cip_train ,ytrain = cip_target):
        
        self.smote_id = smote_id
        self.smote_strat = smote_strat
        self.smote_nbr = k_neighbours
        y = ytrain
        X = xtrain
    
        # smote for contin, smotenc for category
        if(self.smote_id is 'smote'):
            model_id = SMOTE(sampling_strategy=self.smote_strat,
                             k_neighbors=self.smote_nbr)
        elif(self.smote_id is 'smotenc'):
            model_id = SMOTENC(sampling_strategy=self.smote_strat,
                               k_neighbors=self.smote_nbr,
                               categorical_features=[0,1])
        
        X_mod, y_mod = model_id.fit_resample(X,y)
        self.X = pd.concat([X_mod,y_mod],axis=1)
        
        if(self.verbose):
            print(f'\nSMOTE Upsampling: {self.X.shape}')
            print(f'Target Value Counts: \n{pd.Series(y_mod).value_counts()}')
        self.X = pd.concat([X_mod,y_mod],axis=1)

# Defining three models to train the data
clf1 = RandomForestClassifier()
clf2 = LinearDiscriminantAnalysis()
clf3 = KNeighborsClassifier()

# Splitting training and testing data for ciprofloxacin using train_test_split with 0.3 as a test_size
x_cip_train, x_cip_test, y_cip_train, y_cip_test = train_test_split(cip_train, cip_target, test_size=0.3,random_state=0)

clf1.fit(x_cip_train, y_cip_train)
clf2.fit(x_cip_train, y_cip_train)
clf3.fit(x_cip_train, y_cip_train)

pred_cip1 = clf1.predict(x_cip_test)
pred_cip2 = clf2.predict(x_cip_test)
pred_cip3 = clf3.predict(x_cip_test)

print("Random forest on CIP balanced_accuracy_score : ",balanced_accuracy_score(pred_cip1, y_cip_test))
print("LDA on CIP balanced_accuracy_score : ",balanced_accuracy_score(pred_cip2, y_cip_test))
print("KNN on CIP balanced_accuracy_score : ",balanced_accuracy_score(pred_cip3, y_cip_test))

# Defining a voting classifier with random forest, linear discriminative analysis, and Kneighbors as three base estimators
vclf = VotingClassifier(estimators=[('RF', clf1), ('LDA', clf2), ('KNN', clf3)],
                        voting='soft', weights=[2,1,1])

vclf.fit(x_cip_train, y_cip_train)
pred_cip4 = vclf.predict(x_cip_test)

print("Voting Classifier on CIP balanced_accuracy_score : ",balanced_accuracy_score(pred_cip4, y_cip_test))

# AUC of different models on CIP data

y_test = y_cip_test
y_pred_proba = pred_cip1
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for RF, auc="+str(auc))

y_pred_proba = pred_cip2
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for LDA, auc="+str(auc))

y_pred_proba = pred_cip3
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for KNN, auc="+str(auc))

y_pred_proba = pred_cip4
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for Voting CLassifier, auc="+str(auc))

plt.legend(loc=4)

cv = KFold(n_splits=4, random_state=1, shuffle=True)

#use k-fold CV to evaluate each model
scores = cross_val_score(clf1, x_cip_train, y_cip_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("RF - balanced_accuracy_score",mean(absolute(scores)))

scores = cross_val_score(clf2, x_cip_train, y_cip_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("LDA - balanced_accuracy_score",mean(absolute(scores)))

scores = cross_val_score(clf3, x_cip_train, y_cip_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("KNN - balanced_accuracy_score",mean(absolute(scores)))

scores = cross_val_score(vclf, x_cip_train, y_cip_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("Voting Classifier - balanced_accuracy_score",mean(absolute(scores)))

# AZM
# Creating a feature matrix for Azythromycin
case.get_case('azm_sr')

case_azm = case.X

azm_target = case.X[case.target_name]

azm_train = case_azm.drop('azm_sr',axis=1)

print("AZM class distribution : ",case_azm['azm_sr'].value_counts())

#  FOR AZM 
# Splitting train and test data using train_test_split with 0.3 as a test size
x_azm_train, x_azm_test, y_azm_train, y_azm_test = train_test_split(azm_train, azm_target, test_size=0.3,random_state=0)

y = y_azm_train
X = x_azm_train

print("class distribution before SMOTE : ",y_azm_train.value_counts())

unitigs_detail = mod_unitigs(case)

# Applying smote for training data 
unitigs_detail.smote('smotenc',0.4, 6, x_azm_train, y_azm_train)

# model_id = SMOTEN(sampling_strategy=0.4,k_neighbors=6)
# x_azm_train, y_azm_train = model_id.fit_resample(X,y)

print("class distribution after SMOTE : ",y_azm_train.value_counts())

# Feeding training data into all three models
clf1.fit(x_azm_train, y_azm_train)
clf2.fit(x_azm_train, y_azm_train)
clf3.fit(x_azm_train, y_azm_train)

# Predicting using testing data
pred_azm1 = clf1.predict(x_azm_test)
pred_azm2 = clf2.predict(x_azm_test)
pred_azm3 = clf3.predict(x_azm_test)

print("Random forest on AZM balanced_accuracy_score : ",balanced_accuracy_score(pred_azm1, y_azm_test))
print("LDA on AZM balanced_accuracy_score : ",balanced_accuracy_score(pred_azm2, y_azm_test))
print("KNN on AZM balanced_accuracy_score : ",balanced_accuracy_score(pred_azm3, y_azm_test))

vclf.fit(x_azm_train, y_azm_train)
pred_azm4 = vclf.predict(x_azm_test)

print("Voting Classifier on AZM balanced_accuracy_score : ",balanced_accuracy_score(pred_azm4, y_azm_test))

# AUC of different models on AZM data

y_test = y_azm_test
y_pred_proba = pred_azm1
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for RF, auc="+str(auc))

y_pred_proba = pred_azm2
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for LDA, auc="+str(auc))

y_pred_proba = pred_azm3
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for KNN, auc="+str(auc))

y_pred_proba = pred_azm4
fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="AUC for Voting CLassifier, auc="+str(auc))

plt.legend(loc=4)

cv = KFold(n_splits=4, random_state=1, shuffle=True)

#use k-fold CV to evaluate model
scores = cross_val_score(clf1, x_azm_train, y_azm_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("RF",mean(absolute(scores)))

scores = cross_val_score(clf2, x_azm_train, y_azm_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("LDA",mean(absolute(scores)))

scores = cross_val_score(clf3, x_azm_train, y_azm_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("KNN",mean(absolute(scores)))

scores = cross_val_score(vclf, x_azm_train, y_azm_train, scoring='balanced_accuracy',
                         cv=cv, n_jobs=-1)

#view mean absolute error
print("VC",mean(absolute(scores)))

# Creating feature matrix for Cefixime 
case.get_case('cfx_sr')
case_cfx = case.X
cfx_target = case.X[case.target_name]
cfx_train = case_cfx.drop('cfx_sr',axis=1)
print("CFX class distribution : ",case_cfx['cfx_sr'].value_counts())

# Spliiting training and testing data for cefixime using train_test_split with 0.3 as a test size
x_cfx_train, x_cfx_test, y_cfx_train, y_cfx_test = train_test_split(cfx_train, cfx_target, test_size=0.35,random_state=0)
unitigs_detail = mod_unitigs(case)

# We are tryign to decrease the samples of majority class
unitigs_detail.split_case(0.3,x_cfx_train, y_cfx_train)

# Applying smote and upsampling minority class samples
unitigs_detail.smote('smotenc',0.3, 3, x_cfx_train, y_cfx_train)

# Feeding training data of cefixime(CFX) into all the models
clf1.fit(x_cfx_train, y_cfx_train)
clf2.fit(x_cfx_train, y_cfx_train)
clf3.fit(x_cfx_train, y_cfx_train)

# Predicting target labels of CFX testing data 
pred_cfx1 = clf1.predict(x_cfx_test)
pred_cfx2 = clf2.predict(x_cfx_test)
pred_cfx3 = clf3.predict(x_cfx_test)

print("Random forest on CFX balanced_accuracy_score : ",balanced_accuracy_score(pred_cfx1, y_cfx_test))
print("LDA on CFX balanced_accuracy_score : ",balanced_accuracy_score(pred_cfx2, y_cfx_test))
print("KNN on CFX balanced_accuracy_score : ",balanced_accuracy_score(pred_cfx3, y_cfx_test))

vclf.fit(x_cfx_train, y_cfx_train)
pred_cfx4 = vclf.predict(x_cfx_test)

print("Voting Classifier on CFX balanced_accuracy_score : ",balanced_accuracy_score(pred_cfx4, y_cfx_test))

# We can see in the results that the model is being biased towards the majority class and is overfitting. 
# So we cannot perform any considerable evaluation due to insufficient samples.

